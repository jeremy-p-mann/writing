
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>On the “Assessment” of Machine Learning Algorithms &#8212; Jeremy Mann&#39;s Writing 0.0.0 documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Statistical Learning" href="../statistical_learning/statistical_learning_main_page.html" />
    <link rel="prev" title="Machine Learning" href="machine_learning_main_page.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="on-the-assessment-of-machine-learning-algorithms">
<h1>On the “Assessment” of Machine Learning Algorithms<a class="headerlink" href="#on-the-assessment-of-machine-learning-algorithms" title="Permalink to this headline">¶</a></h1>
<p>The primary difference between statistical inference and statistical learning is how they are assessed:</p>
<ul class="simple">
<li><p>One <strong>validates</strong> the conclusions of <strong>statistical inference</strong> (hypothesis test)</p></li>
<li><p>One <strong>simulates</strong> the outcomes of the deployment of <strong>machine learning</strong> algorithms.</p></li>
</ul>
<p>Validation has to do with the relative likelihood of data given hypotheses. For example, likelihood ratios and relative entropies are validation metrics.</p>
<p>A classic example of an assessment is the Expected Value Framework.</p>
<p>In some instances, these approaches agree. For example, when the repurcussions of a mistake are indistinguishable.</p>
<div class="section" id="applications-of-inference-to-learning">
<h2>Applications of Inference to Learning<a class="headerlink" href="#applications-of-inference-to-learning" title="Permalink to this headline">¶</a></h2>
<p>Many validation metrics admit a (fairly) smooth, analytic description which can be exploited by optimization strategies based upon gradient descent.</p>
<p>This forms the basis of a common technique: instead of optimizing for the outcome directly, optimize over a validation metric on a modified data set. The specifics of the modification encode one’s understanding of the consequences of the model’s deployment.</p>
<p>For example, in medical diagnostics, one frequently encounters the problem of detecting a condition which only exists in a minority of individuals, and the misassignment of a member of the minority population (i.e. a false negative) is disproportionately great.</p>
<p>In this situation, deploying a model trained to optimize validation metrics would be a disaster: modification of the data is necessary for its sucessful deployment.</p>
<p>One common modification strategy is to engineer the empirical probability distrubtion of the classes, as this dictates how strongly each class contributes to the validation metric. Hopefully, this engineering will amplify the effect of the introduction of a false negative, which will in turn motivate the algorithm to perform better on the minority class (most likely at the cost of false positives).</p>
<p>Common strategies are:</p>
<ul class="simple">
<li><p>oversampling the minority</p></li>
<li><p>undersampling the majority</p></li>
<li><p>directly altering the class weights in a loss function.</p></li>
</ul>
</div>
<div class="section" id="applications-of-learning-to-inference">
<h2>Applications of Learning to Inference<a class="headerlink" href="#applications-of-learning-to-inference" title="Permalink to this headline">¶</a></h2>
<p>Learning can amplify the statistical significance of a hypothesis test. In other words, increase the effect size. There are two ways to increase the effect size: increase the effect or decrease the variance.</p>
<p>Learners can increase the effect by forming an exclusion criteria, thereby selecting individuals suceptible to the intervention.</p>
<p>Learners can decrease the variance by learning optimal pairings or generating simulated samples.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Jeremy Mann's Writing</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../learning_main_page.html">Learning</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="machine_learning_main_page.html">Machine Learning</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">On the “Assessment” of Machine Learning Algorithms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../statistical_learning/statistical_learning_main_page.html">Statistical Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../statistical_inference/statistical_inference_main_page.html">Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_science/data_science_main_page.html">Data Science</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../math/math_main_page.html">Math</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../physics/physics_main_page.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../longevity/longevity_main_page.html">Longevity</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../random/random_main_page.html">Random Writing</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../learning_main_page.html">Learning</a><ul>
  <li><a href="machine_learning_main_page.html">Machine Learning</a><ul>
      <li>Previous: <a href="machine_learning_main_page.html" title="previous chapter">Machine Learning</a></li>
      <li>Next: <a href="../statistical_learning/statistical_learning_main_page.html" title="next chapter">Statistical Learning</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Jeremy Mann.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/learning/machine_learning/on_assessing_machine_learning_algorithms.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>