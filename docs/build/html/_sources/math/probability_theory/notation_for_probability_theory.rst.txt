Notation For Probability Theory
===============================

Personally, I find the notation and language conventionally used in probability theory imprecise to the point of confusion. This becomes especially apparent when discussing the zoo of notions of error in statistical learning. To quote *Elements of Statistical Learning*:

	Discussions of error rate estimation can be confusing, because we have to make clear which quantities are ﬁxed and which are random... Indeed, in the ﬁrst edition of our book, this section wasn’t suﬃciently clear.

The text below is purely technical, but we hope that making these essential notions explicit justifies the tedium.



Since we're talking about probablility, it will be helpful to have notation for probability distributions which have the same, explicit scope.

.. admonition:: Definition

   Given a set :math:`S`, we let 

   .. math::
      \mathrm{Prob}(S)

   denote the set of probability distributions on :math:`S`. 

The next two definitions shows us how to use functions between sets to make new probability distributions.

.. admonition:: Definition: Pushforward

   A map of sets:

   .. math::

      S_0 \overset{f} \longrightarrow S_1

   induces a map of probability distributions:

   .. math::

      \begin{align*}
      \mathrm{Prob}(S_0) &\overset{f_*} \longrightarrow \mathrm{Prob}(S_1) \\
      \rho \longmapsto& \bigl[U \subset S_0  \mapsto (f_*\rho)(U) := \rho(f^{-1}(U)) \bigl]
      \end{align*}

   called the pushforward along :math:`f`. We call :math:`f_*(\rho)` the pushforward of :math:`\rho` along :math:`f` 

An example to keep in mind is when :math:`S` admits a factorization as:

.. math::

   S \simeq X \times Y

and :math:`f` is a projection:

.. math::

   \begin{align*}
   X \times Y &\overset{\pi^Y}\longrightarrow X \\
   (x, y) &\longmapsto x
   \end{align*}

In this case, given a probability distribution :math:`\rho \in \mathrm{Prob}(X \times Y)`, 

.. math:: 

   \pi^Y_*(\rho)

is commonly referred to as the marginal distribution of X. It is computed through integration:

.. math:: 

   (\pi^Y)_*(\rho)(x) = \int_Y  \rho(x, y) \mathrm{d}y

.. warning::
   
   By convention, when :math:`X` is a finite set, integration coincides with summation.
.. note:: 
 
   Conventionally, one would indicate that the input of :math:`\rho` is a tuple :math:`(x, y) \in X \times Y` by writing :math:`\rho(x, y)`. 

   This is problematic, as it is unclear whether one is referring to the distribution :math:`\rho` or the number :math:`\rho(x, y)`. In other words, it promotes type errors. Explicit is better than implicit.

When :math:`f` is an inclusion of a subset, we can generate probability distributions 'contravariantly':

.. admonition:: Definition

   Given an inclusion of a subset: 

   .. math::

      A \overset{\iota_A}\longrightarrow X

   we can restrict a probability distribution :math:`P` to :math:`A`

   .. math::

      \begin{align*}
      \mathrm{Prob}(S_0) &\overset{\iota_A^*} \longrightarrow \mathrm{Prob}(S_1) \\
      P &\longmapsto (\iota^*P)(A) := P(-|A) =: P|_A 
      \end{align*}

   conventionally referred to as the conditional distribution. We will refer to :math:`\rho|A` as :math:`\rho` restricted to :math:`A`.

As an example of how these can be used, note that entropy intertwines pushforwards with restrictions.

.. math::


